{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psychometric Analysis\n",
    "\n",
    "## To be used with Google Colab\n",
    "1. https://colab.research.google.com/\n",
    "2. Choose **Github**\n",
    "3. Paste the url **`https://github.com/shlomihod/psypsy/blob/master/psychometric-analysis.ipynb`**\n",
    "4. Click on **NEW PYTHON 3 NOTEBOOK**\n",
    "5. Click on **Runtime** and then **Run All**\n",
    "6. Upload **`responses.xlsx`** file\n",
    "7. Print as PDF\n",
    "\n",
    "\n",
    "## Useful Reference:\n",
    "https://www.creighton.edu/sites/www12.creighton.edu/files/PtT-Exam%20Analysis.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILENAME = 'responses.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "          name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert DATA_FILENAME in uploaded\n",
    "\n",
    "with open(DATA_FILENAME, 'wb') as f:\n",
    "    f.write(uploaded[DATA_FILENAME])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.read_excel(DATA_FILENAME, sheet_name='responses')\n",
    "\n",
    "answer_key_df = pd.read_excel(DATA_FILENAME, sheet_name='key')\n",
    "\n",
    "ITEM_COLS = {col : col + '_is_correct'\n",
    "             for col in responses.columns if 'item' in col}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not responses.isnull().any().any()\n",
    "\n",
    "assert not responses.duplicated().any()\n",
    "assert not responses['id'].duplicated().any()\n",
    "assert not responses['name'].duplicated().any()\n",
    "\n",
    "assert responses['gender'].isin({'M', 'F'}).all()\n",
    "assert responses['class'].isin({10, 11, 12}).all()\n",
    "assert responses[list(ITEM_COLS.keys())].isin({1, 2, 3, 4}).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(answer_key_df.columns == list(ITEM_COLS.keys()))\n",
    "assert len(answer_key_df) == 1\n",
    "\n",
    "answer_key = answer_key_df.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Score and `is_correct` Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, col_is_correct in ITEM_COLS.items():\n",
    "    responses[col_is_correct] = (responses[col]\n",
    "                                      == answer_key[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['score'] = responses[list(ITEM_COLS.values())].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score - Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(responses['score']\n",
    " .describe(percentiles=np.arange(0, 1, 0.1))\n",
    " .round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(responses['score'])\n",
    "\n",
    "plt.title('Score Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(responses['score'],\n",
    "             hist_kws={'cumulative': True},\n",
    "             kde_kws={'cumulative': True})\n",
    "\n",
    "plt.title('Score Cumulative Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability - Internal Consistency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code & Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cronbach_alpha_KR20(items):\n",
    "    \"\"\"Calculate KR20 for dichotomous items.\n",
    "    \n",
    "    # https://github.com/anthropedia/tci-stats\n",
    "    \"\"\"\n",
    "    items = pd.DataFrame(items)\n",
    "    items_count = items.shape[1]\n",
    "    \n",
    "    # note: probably ddof need to be changed to 1 for non-dichotomous items.\n",
    "    variance_sum = items.var(axis=0, ddof=0).sum()\n",
    "    \n",
    "    total_var = items.sum(axis=1).var(ddof=1)\n",
    "    \n",
    "    return (items_count / (items_count - 1) *\n",
    "            (1 - variance_sum / total_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.hr-survey.com/WpAssessmentHandbook.htm\n",
    "# Estimating Reliability using the Kuder-Richardson Formula 20\n",
    "\n",
    "\n",
    "ca_test_data =\"\"\"N\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
    "A\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\n",
    "B\t1\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t0\n",
    "C\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t0\t0\n",
    "D\t1\t1\t1\t0\t1\t1\t0\t1\t1\t0\t0\t0\n",
    "E\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\n",
    "F\t1\t1\t1\t0\t0\t1\t1\t0\t0\t1\t0\t0\n",
    "G\t1\t1\t1\t1\t0\t0\t1\t0\t0\t0\t0\t0\n",
    "H\t1\t1\t0\t1\t0\t0\t0\t1\t0\t0\t0\t0\n",
    "I\t1\t1\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\n",
    "J\t0\t0\t0\t1\t1\t0\t0\t0\t0\t0\t0\t0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_test_df = (pd.DataFrame({col: data\n",
    "                  for col, *data in\n",
    "                  zip(*(row.split()\n",
    "                        for row in ca_test_data.splitlines()))\n",
    "                 })\n",
    "              .set_index('N')\n",
    "              .astype(int))\n",
    "\n",
    "assert np.isclose(cronbach_alpha_KR20(ca_test_df), 0.8, atol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Reliability\n",
    "\n",
    "| Cronbach's alpha | Internal consistency |\n",
    "|------------------|----------------------|\n",
    "| 0.9 ≤ α          | Excellent            |\n",
    "| 0.8 ≤ α < 0.9    | Good                 |\n",
    "| 0.7 ≤ α < 0.8    | Acceptable           |\n",
    "| 0.6 ≤ α < 0.7    | Questionable         |\n",
    "| 0.5 ≤ α < 0.6    | Poor                 |\n",
    "| α < 0.5          | Unacceptable         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cronbach_alpha_KR20(responses[list(ITEM_COLS.values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbs(item):\n",
    "     return stats.pointbiserialr(item,\n",
    "                                 responses['score'])[0]\n",
    "\n",
    "item_statistics = (responses[list(ITEM_COLS.values())]\n",
    "                   .agg(['mean', 'std', pbs])\n",
    "                   .transpose()\n",
    "                   .rename({'mean': 'proportion'}, axis=1)\n",
    "                  )\n",
    "\n",
    "item_statistics['reliability_without'] = item_statistics.index.map(lambda item: \n",
    "                                        cronbach_alpha_KR20(responses[list(ITEM_COLS.values())]\n",
    "                                                            .drop(item, axis=1)))\n",
    "\n",
    "item_statistics = (item_statistics.round(3)\n",
    "                                  .rename(index=lambda x: x.split('_')[0]))\n",
    "\n",
    "item_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_statistics[['proportion', 'pbs']].plot()\n",
    "\n",
    "plt.title('Difficulty and Discrimination per Item');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_statistics['proportion'].plot(kind='bar')\n",
    "\n",
    "plt.title('Difficulty per Item');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_statistics.sort_values('proportion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Item Analysis\n",
    "(with colab anti-collapse ugly hack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def perform_responses_per_item_analysis(df, cols):\n",
    "    for col in cols:\n",
    "\n",
    "        responses_per_item = (df\n",
    "                              .groupby([col])['score']\n",
    "                              .agg(['size', 'mean']))\n",
    "\n",
    "        responses_per_item['proportion'] = (responses_per_item['size']\n",
    "                                            / responses_per_item['size']).sum()\n",
    "\n",
    "        responses_per_item = responses_per_item.round(3)\n",
    "\n",
    "        responses_per_item = responses_per_item[['mean', 'size', 'proportion']]\n",
    "\n",
    "        responses_per_item.index = responses_per_item.index.astype(str)\n",
    "\n",
    "        responses_per_item = responses_per_item.rename(index = {str(answer_key[col]):\n",
    "                                                                '*' + str(answer_key[col])})\n",
    "        display(responses_per_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_responses_per_item_analysis(responses, list(ITEM_COLS.keys())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_responses_per_item_analysis(responses, list(ITEM_COLS.keys())[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_responses_per_item_analysis(responses, list(ITEM_COLS.keys())[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_responses_per_item_analysis(responses, list(ITEM_COLS.keys())[15:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_responses_per_item_analysis(responses, list(ITEM_COLS.keys())[20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_responses_per_item_analysis(responses, list(ITEM_COLS.keys())[25:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis By Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_by_gender = responses.groupby('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(responses_by_gender['score']\n",
    " .describe(percentiles=np.arange(0, 1, 0.1))\n",
    " .round(3).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, group in responses_by_gender:\n",
    "    sns.distplot(group['score'], label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Score Distribution by Gender');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, group in responses_by_gender:\n",
    "    sns.distplot(group['score'],\n",
    "                 hist_kws={'cumulative': True},\n",
    "                 kde_kws={'cumulative': True})\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Score Cumulative Distribution by Gender');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis By Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_by_class = responses.groupby('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(responses_by_class['score']\n",
    " .describe(percentiles=np.arange(0, 1, 0.1))\n",
    " .round(3).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, group in responses_by_class:\n",
    "    sns.distplot(group['score'], label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Score Distribution by Class');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, group in responses_by_class:\n",
    "    sns.distplot(group['score'],\n",
    "                 hist_kws={'cumulative': True},\n",
    "                 kde_kws={'cumulative': True})\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Score Cumulative Distribution by Class');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
